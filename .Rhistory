set.seed(12345)
0.6*row
trainindex <- sample(row, 0.6*row, replace=FALSE)
training <- mydata[trainindex,]
validation <- mydata[-trainindex,]
myforest <- randomForest(as.factor(left)~., data=training)
K_Means_Data
install.packages("randomForest")
library(randomForest)
traindata=K_Means_Data
traindata
mydata=traindata
row<-nrow(mydata)
set.seed(12345)
0.6*row
trainindex <- sample(row, 0.6*row, replace=FALSE)
training <- mydata[trainindex,]
validation <- mydata[-trainindex,]
myforest <- randomForest(as.factor(left)~., data=training)
myforest
importance(myforest)
varImpPlot(myforest)
predforest <- predict(myforest, validation)
predforest
conf_matrix <- table(validation$left, predforest)
conf_matrix
miss_class  <- 1 -sum(diag(matrix))/sum(matrix)
miss_class
Accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
Accuracy
KMeansData <- read.csv("HR_comma.csv", header=T, stringsAsFactors=F)
normalize <- function(x){(x - min(x)) / (max(x) - min(x))}
DF <- data.frame(KMeansData)
KMeansData <- as.data.frame(lapply(DF[1:8], normalize))
traindata <- KMeansData
str(traindata)
names(traindata) <- gsub("_","",names(traindata))
summary(traindata)
traindata <- traindata[complete.cases(traindata),]
traindata[traindata==""] <- NA
traindata$left <- as.factor(traindata$left)
set.seed(12345)
borutaTrain <- Boruta(left~., data=traindata, doTrace=2)
install.packages("randomForest")
install.packages("Boruta")
install.packages("ROCR")
library(randomForest)
library(Boruta)
library(ROCR)
K_Means_Data <- read.csv("HR_comma.csv", header = T, stringsAsFactors = F)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
DF=data.frame(K_Means_Data)
K_Means_Data <- as.data.frame(lapply(DF[1:8], normalize))
K_Means_Data
traindata=K_Means_Data
str(traindata)
names(traindata) <- gsub("_", "", names(traindata))
summary(traindata)
traindata <- traindata[complete.cases(traindata),]
traindata[traindata == ""] <- NA
traindata$left <- as.factor(traindata$left)
set.seed(12345)
boruta.train <- Boruta(left~., data = traindata, doTrace = 2)
install.packages("Boruta", dependencies=TRUE)
library(Boruta)
K_Means_Data <- read.csv("HR_comma.csv", header = T, stringsAsFactors = F)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
DF=data.frame(K_Means_Data)
K_Means_Data <- as.data.frame(lapply(DF[1:8], normalize))
K_Means_Data
traindata=K_Means_Data
str(traindata)
names(traindata) <- gsub("_", "", names(traindata))
summary(traindata)
traindata <- traindata[complete.cases(traindata),]
traindata[traindata == ""] <- NA
traindata$left <- as.factor(traindata$left)
set.seed(12345)
boruta.train <- Boruta(left~., data = traindata, doTrace = 2)
print(boruta.train)
plot(boruta.train, xlab = "", xaxt = "n")
lz<-lapply(1:ncol(boruta.train$ImpHistory),function(i) boruta.train$ImpHistory[is.finite(boruta.train$ImpHistory[,i]),i])
names(lz) <- colnames(boruta.train$ImpHistory)
Labels <- sort(sapply(lz,median))
axis(side = 1,las=2,labels = names(Labels), at = 1:ncol(boruta.train$ImpHistory), cex.axis = 0.7)
final.boruta <- TentativeRoughFix(boruta.train)
print(final.boruta)
boruta.df <- attStats(final.boruta)
class(boruta.df)
print(boruta.df)
library(ROCR)
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
mylogit <- glm(as.factor(left)~satisfactionlevel+lastevaluation+numberproject+averagemontlyhours+timespendcompany+Workaccident+promotionlast5years, data=training, family=binomial)
summary(mylogit)
coef(mylogit)
mylogitProbs <- predict(mylogit, validation, type="response")
confusionMatrix <- function(actual, predictedProb, threshold=0.5){pred <- ifelse(predictedProb>threshold,1,0); table(Predicted=pred, Actual=actual)}
accuracy <- function(actual, predictedProb, threshold=0.5){pred <- ifelse(predictedProb>threshold,1,0); cm <- table(Predicted=pred, Actual=actual); sum(diag(cm))/sum(cm)}
matrix <- confusionMatrix(validation$left, mylogitProbs, threshold=0.35)
acc <- accuracy(validation$left, mylogitProbs, threshold=0.35)
missClass <- 1 - sum(diag(matrix))/sum(matrix)
accuracyValue <- sum(diag(matrix))/sum(matrix)
mydf <- cbind(validation, mylogitProbs)
mydf$response <- as.factor(ifelse(mydf$mylogitProbs>0.5,1,0))
logitScores <- prediction(mydf$mylogitProbs, labels=mydf$left)
logitPerf <- performance(logitScores, "tpr", "fpr")
plot(logitPerf, main="ROC Curve", xlab="1 - Specificity", ylab="Sensitivity", col="blue", lwd=3)
abline(0,1,lty=2,col="red")
logitAuc <- performance(logitScores, "auc")
as.numeric([logitAuc@y.values](mailto:logitAuc@y.values))
library(ROCR)
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
mylogit <- glm(as.factor(left)~satisfactionlevel+lastevaluation+numberproject+averagemontlyhours+timespendcompany+Workaccident+promotionlast5years, data=training, family=binomial)
summary(mylogit)
coef(mylogit)
mylogitProbs <- predict(mylogit, validation, type="response")
confusionMatrix <- function(actual, predictedProb, threshold=0.5){pred <- ifelse(predictedProb>threshold,1,0); table(Predicted=pred, Actual=actual)}
accuracy <- function(actual, predictedProb, threshold=0.5){pred <- ifelse(predictedProb>threshold,1,0); cm <- table(Predicted=pred, Actual=actual); sum(diag(cm))/sum(cm)}
matrix <- confusionMatrix(validation$left, mylogitProbs, threshold=0.35)
acc <- accuracy(validation$left, mylogitProbs, threshold=0.35)
missClass <- 1 - sum(diag(matrix))/sum(matrix)
accuracyValue <- sum(diag(matrix))/sum(matrix)
mydf <- cbind(validation, mylogitProbs)
mydf$response <- as.factor(ifelse(mydf$mylogitProbs>0.5,1,0))
logitScores <- prediction(mydf$mylogitProbs, labels=mydf$left)
logitPerf <- performance(logitScores, "tpr", "fpr")
plot(logitPerf, main="ROC Curve", xlab="1 - Specificity", ylab="Sensitivity", col="blue", lwd=3)
abline(0,1,lty=2,col="red")
logitAuc <- performance(logitScores, "auc")
as.numeric(Auc@y.values)
library(ROCR)
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
mylogit <- glm(as.factor(left)~satisfactionlevel+lastevaluation+numberproject+averagemontlyhours+timespendcompany+Workaccident+promotionlast5years, data=training, family=binomial)
summary(mylogit)
coef(mylogit)
mylogitProbs <- predict(mylogit, validation, type="response")
confusionMatrix <- function(actual, predictedProb, threshold=0.5){pred <- ifelse(predictedProb>threshold,1,0); table(Predicted=pred, Actual=actual)}
accuracy <- function(actual, predictedProb, threshold=0.5){pred <- ifelse(predictedProb>threshold,1,0); cm <- table(Predicted=pred, Actual=actual); sum(diag(cm))/sum(cm)}
matrix <- confusionMatrix(validation$left, mylogitProbs, threshold=0.35)
acc <- accuracy(validation$left, mylogitProbs, threshold=0.35)
missClass <- 1 - sum(diag(matrix))/sum(matrix)
accuracyValue <- sum(diag(matrix))/sum(matrix)
mydf <- cbind(validation, mylogitProbs)
mydf$response <- as.factor(ifelse(mydf$mylogitProbs>0.5,1,0))
logitScores <- prediction(mydf$mylogitProbs, labels=mydf$left)
logitPerf <- performance(logitScores, "tpr", "fpr")
plot(logitPerf, main="ROC Curve", xlab="1 - Specificity", ylab="Sensitivity", col="blue", lwd=3)
abline(0,1,lty=2,col="red")
logitAuc <- performance(logitScores, "auc")
as.numeric(logitAuc@y.values)
logitLift <- performance(logitScores, measure="lift", x.measure="rpp")
plot(logitLift, main="Lift Chart", xlab="% Population", ylab="Lift", col="darkblue", lwd=3)
abline(1,0,col="red",lwd=3)
grid(col="aquamarine")
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
mylogit <- glm(as.factor(left)~satisfactionlevel+lastevaluation+numberproject+averagemontlyhours+timespendcompany+Workaccident+promotionlast5years, data=training, family=binomial)
backward <- step(mylogit, direction='backward')
mylogit <- backward
mylogitProbs <- predict(mylogit, validation, type="response")
matrix <- confusionMatrix(validation$left, mylogitProbs, threshold=0.35)
acc <- accuracy(validation$left, mylogitProbs, threshold=0.35)
missClass <- 1 - sum(diag(matrix))/sum(matrix)
accuracyValue <- sum(diag(matrix))/sum(matrix)
mydf <- cbind(validation, mylogitProbs)
mydf$response <- as.factor(ifelse(mydf$mylogitProbs>0.5,1,0))
logitScores <- prediction(mydf$mylogitProbs, labels=mydf$left)
logitPerf <- performance(logitScores, "tpr", "fpr")
plot(logitPerf, main="ROC Curve", xlab="1 - Specificity", ylab="Sensitivity", col="darkblue", lwd=3)
abline(0,1,lty=3,col="green",lwd=3)
grid(col="aquamarine")
logitAuc <- performance(logitScores, "auc")
as.numeric([logitAuc@y.values]
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
mylogit <- glm(as.factor(left)~satisfactionlevel+lastevaluation+numberproject+averagemontlyhours+timespendcompany+Workaccident+promotionlast5years, data=training, family=binomial)
backward <- step(mylogit, direction='backward')
mylogit <- backward
mylogitProbs <- predict(mylogit, validation, type="response")
matrix <- confusionMatrix(validation$left, mylogitProbs, threshold=0.35)
acc <- accuracy(validation$left, mylogitProbs, threshold=0.35)
missClass <- 1 - sum(diag(matrix))/sum(matrix)
accuracyValue <- sum(diag(matrix))/sum(matrix)
mydf <- cbind(validation, mylogitProbs)
mydf$response <- as.factor(ifelse(mydf$mylogitProbs>0.5,1,0))
logitScores <- prediction(mydf$mylogitProbs, labels=mydf$left)
logitPerf <- performance(logitScores, "tpr", "fpr")
plot(logitPerf, main="ROC Curve", xlab="1 - Specificity", ylab="Sensitivity", col="darkblue", lwd=3)
abline(0,1,lty=3,col="green",lwd=3)
grid(col="aquamarine")
logitAuc <- performance(logitScores, "auc")
as.numeric(logitAuc@y.values)
logitLift <- performance(logitScores, measure="lift", x.measure="rpp")
plot(logitLift, main="Lift Chart", xlab="% Population", ylab="Lift", col="darkblue", lwd=3)
abline(1,0,col="red",lwd=3)
grid(col="aquamarine")
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(party)
library(partykit)
library(caret)
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
classTree <- rpart(as.factor(left)~., data=training, method="class")
plot(classTree)
text(classTree)
prp(classTree)
rpart.plot(classTree, type=1, extra=102)
predTree <- predict(classTree, validation, type="class")
matrix <- table(validation[,1], predTree)
missClass <- 1 - sum(diag(matrix))/sum(matrix)
accuracyValue <- sum(diag(matrix))/sum(matrix)
library(randomForest)
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
myforest <- randomForest(as.factor(left)~., data=training)
importance(myforest)
varImpPlot(myforest)
predForest <- predict(myforest, validation)
confMatrix <- table(validation$left, predForest)
missClass <- 1 - sum(diag(confMatrix))/sum(confMatrix)
accuracyValue <- sum(diag(confMatrix))/sum(confMatrix)
accuracyValue
install.packages("randomForest")
install.packages("Boruta")
install.packages("ROCR")
library(randomForest)
library(Boruta)
library(ROCR)
install.packages("ROCR")
install.packages("Boruta", dependencies=TRUE)
library(Boruta)
K_Means_Data <- read.csv("final.csv", header = T, stringsAsFactors = F)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
DF=data.frame(K_Means_Data)
K_Means_Data <- as.data.frame(lapply(DF[1:8], normalize))
K_Means_Data
traindata=K_Means_Data
str(traindata)
names(traindata) <- gsub("_", "", names(traindata))
summary(traindata)
traindata <- traindata[complete.cases(traindata),]
traindata[traindata == ""] <- NA
traindata$left <- as.factor(traindata$left)
set.seed(12345)
boruta.train <- Boruta(left~., data = traindata, doTrace = 2)
install.packages("Boruta", dependencies = TRUE)
print(boruta.train)
plot(boruta.train, xlab = "", xaxt = "n")
lz<-lapply(1:ncol(boruta.train$ImpHistory),function(i) boruta.train$ImpHistory[is.finite(boruta.train$ImpHistory[,i]),i])
names(lz) <- colnames(boruta.train$ImpHistory)
Labels <- sort(sapply(lz,median))
axis(side = 1,las=2,labels = names(Labels), at = 1:ncol(boruta.train$ImpHistory), cex.axis = 0.7)
final.boruta <- TentativeRoughFix(boruta.train)
print(final.boruta)
boruta.df <- attStats(final.boruta)
class(boruta.df)
print(boruta.df)
library(ROCR)
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
mylogit <- glm(as.factor(left)~satisfactionlevel+lastevaluation+numberproject+averagemontlyhours+timespendcompany+Workaccident+promotionlast5years, data=training, family=binomial)
summary(mylogit)
coef(mylogit)
mylogitProbs <- predict(mylogit, validation, type="response")
confusionMatrix <- function(actual, predictedProb, threshold=0.5){pred <- ifelse(predictedProb>threshold,1,0); table(Predicted=pred, Actual=actual)}
accuracy <- function(actual, predictedProb, threshold=0.5){pred <- ifelse(predictedProb>threshold,1,0); cm <- table(Predicted=pred, Actual=actual); sum(diag(cm))/sum(cm)}
matrix <- confusionMatrix(validation$left, mylogitProbs, threshold=0.35)
acc <- accuracy(validation$left, mylogitProbs, threshold=0.35)
missClass <- 1 - sum(diag(matrix))/sum(matrix)
accuracyValue <- sum(diag(matrix))/sum(matrix)
mydf <- cbind(validation, mylogitProbs)
mydf$response <- as.factor(ifelse(mydf$mylogitProbs>0.5,1,0))
logitScores <- prediction(mydf$mylogitProbs, labels=mydf$left)
logitPerf <- performance(logitScores, "tpr", "fpr")
plot(logitPerf, main="ROC Curve", xlab="1 - Specificity", ylab="Sensitivity", col="blue", lwd=3)
abline(0,1,lty=2,col="red")
logitAuc <- performance(logitScores, "auc")
as.numeric(logitAuc@y.values)
logitLift <- performance(logitScores, measure="lift", x.measure="rpp")
plot(logitLift, main="Lift Chart", xlab="% Population", ylab="Lift", col="darkblue", lwd=3)
abline(1,0,col="red",lwd=3)
grid(col="aquamarine")
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
mylogit <- glm(as.factor(left)~satisfactionlevel+lastevaluation+numberproject+averagemontlyhours+timespendcompany+Workaccident+promotionlast5years, data=training, family=binomial)
backward <- step(mylogit, direction='backward')
mylogit <- backward
mylogitProbs <- predict(mylogit, validation, type="response")
matrix <- confusionMatrix(validation$left, mylogitProbs, threshold=0.35)
acc <- accuracy(validation$left, mylogitProbs, threshold=0.35)
missClass <- 1 - sum(diag(matrix))/sum(matrix)
accuracyValue <- sum(diag(matrix))/sum(matrix)
mydf <- cbind(validation, mylogitProbs)
mydf$response <- as.factor(ifelse(mydf$mylogitProbs>0.5,1,0))
logitScores <- prediction(mydf$mylogitProbs, labels=mydf$left)
logitPerf <- performance(logitScores, "tpr", "fpr")
plot(logitPerf, main="ROC Curve", xlab="1 - Specificity", ylab="Sensitivity", col="darkblue", lwd=3)
abline(0,1,lty=3,col="green",lwd=3)
grid(col="aquamarine")
logitAuc <- performance(logitScores, "auc")
as.numeric(logitAuc@y.values)
logitLift <- performance(logitScores, measure="lift", x.measure="rpp")
plot(logitLift, main="Lift Chart", xlab="% Population", ylab="Lift", col="darkblue", lwd=3)
abline(1,0,col="red",lwd=3)
grid(col="aquamarine")
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(party)
library(partykit)
library(caret)
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
classTree <- rpart(as.factor(left)~., data=training, method="class")
plot(classTree)
text(classTree)
prp(classTree)
rpart.plot(classTree, type=1, extra=102)
predTree <- predict(classTree, validation, type="class")
matrix <- table(validation[,1], predTree)
missClass <- 1 - sum(diag(matrix))/sum(matrix)
accuracyValue <- sum(diag(matrix))/sum(matrix)
library(randomForest)
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
myforest <- randomForest(as.factor(left)~., data=training)
importance(myforest)
install.packages("randomForest")
install.packages("Boruta")
install.packages("ROCR")
library(randomForest)
library(Boruta)
library(ROCR)
install.packages("Boruta", dependencies=TRUE)
library(Boruta)
K_Means_Data <- read.csv("final.csv", header = T, stringsAsFactors = F)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
DF=data.frame(K_Means_Data)
K_Means_Data <- as.data.frame(lapply(DF[1:8], normalize))
K_Means_Data
traindata=K_Means_Data
str(traindata)
names(traindata) <- gsub("_", "", names(traindata))
summary(traindata)
traindata <- traindata[complete.cases(traindata),]
traindata[traindata == ""] <- NA
traindata$left <- as.factor(traindata$left)
set.seed(12345)
boruta.train <- Boruta(left~., data = traindata, doTrace = 2)
print(boruta.train)
plot(boruta.train, xlab = "", xaxt = "n")
lz<-lapply(1:ncol(boruta.train$ImpHistory),function(i) boruta.train$ImpHistory[is.finite(boruta.train$ImpHistory[,i]),i])
names(lz) <- colnames(boruta.train$ImpHistory)
Labels <- sort(sapply(lz,median))
axis(side = 1,las=2,labels = names(Labels), at = 1:ncol(boruta.train$ImpHistory), cex.axis = 0.7)
final.boruta <- TentativeRoughFix(boruta.train)
print(final.boruta)
boruta.df <- attStats(final.boruta)
class(boruta.df)
print(boruta.df)
library(ROCR)
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
mylogit <- glm(as.factor(left)~satisfactionlevel+lastevaluation+numberproject+averagemontlyhours+timespendcompany+Workaccident+promotionlast5years, data=training, family=binomial)
summary(mylogit)
coef(mylogit)
mylogitProbs <- predict(mylogit, validation, type="response")
confusionMatrix <- function(actual, predictedProb, threshold=0.5){pred <- ifelse(predictedProb>threshold,1,0); table(Predicted=pred, Actual=actual)}
accuracy <- function(actual, predictedProb, threshold=0.5){pred <- ifelse(predictedProb>threshold,1,0); cm <- table(Predicted=pred, Actual=actual); sum(diag(cm))/sum(cm)}
matrix <- confusionMatrix(validation$left, mylogitProbs, threshold=0.35)
acc <- accuracy(validation$left, mylogitProbs, threshold=0.35)
missClass <- 1 - sum(diag(matrix))/sum(matrix)
accuracyValue <- sum(diag(matrix))/sum(matrix)
mydf <- cbind(validation, mylogitProbs)
mydf$response <- as.factor(ifelse(mydf$mylogitProbs>0.5,1,0))
logitScores <- prediction(mydf$mylogitProbs, labels=mydf$left)
logitPerf <- performance(logitScores, "tpr", "fpr")
plot(logitPerf, main="ROC Curve", xlab="1 - Specificity", ylab="Sensitivity", col="blue", lwd=3)
abline(0,1,lty=2,col="red")
logitAuc <- performance(logitScores, "auc")
as.numeric(logitAuc@y.values)
logitLift <- performance(logitScores, measure="lift", x.measure="rpp")
plot(logitLift, main="Lift Chart", xlab="% Population", ylab="Lift", col="darkblue", lwd=3)
abline(1,0,col="red",lwd=3)
grid(col="aquamarine")
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
mylogit <- glm(as.factor(left)~satisfactionlevel+lastevaluation+numberproject+averagemontlyhours+timespendcompany+Workaccident+promotionlast5years, data=training, family=binomial)
backward <- step(mylogit, direction='backward')
mylogit <- backward
mylogitProbs <- predict(mylogit, validation, type="response")
matrix <- confusionMatrix(validation$left, mylogitProbs, threshold=0.35)
acc <- accuracy(validation$left, mylogitProbs, threshold=0.35)
missClass <- 1 - sum(diag(matrix))/sum(matrix)
accuracyValue <- sum(diag(matrix))/sum(matrix)
mydf <- cbind(validation, mylogitProbs)
mydf$response <- as.factor(ifelse(mydf$mylogitProbs>0.5,1,0))
logitScores <- prediction(mydf$mylogitProbs, labels=mydf$left)
logitPerf <- performance(logitScores, "tpr", "fpr")
plot(logitPerf, main="ROC Curve", xlab="1 - Specificity", ylab="Sensitivity", col="darkblue", lwd=3)
abline(0,1,lty=3,col="green",lwd=3)
grid(col="aquamarine")
logitAuc <- performance(logitScores, "auc")
as.numeric(logitAuc@y.values)
logitLift <- performance(logitScores, measure="lift", x.measure="rpp")
plot(logitLift, main="Lift Chart", xlab="% Population", ylab="Lift", col="darkblue", lwd=3)
abline(1,0,col="red",lwd=3)
grid(col="aquamarine")
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(party)
library(partykit)
library(caret)
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
classTree <- rpart(as.factor(left)~., data=training, method="class")
plot(classTree)
text(classTree)
prp(classTree)
rpart.plot(classTree, type=1, extra=102)
predTree <- predict(classTree, validation, type="class")
matrix <- table(validation[,1], predTree)
missClass <- 1 - sum(diag(matrix))/sum(matrix)
accuracyValue <- sum(diag(matrix))/sum(matrix)
library(randomForest)
mydata <- KMeansData
rows <- nrow(mydata)
set.seed(12345)
trainIndex <- sample(rows, 0.6*rows, replace=FALSE)
training <- mydata[trainIndex,]
validation <- mydata[-trainIndex,]
myforest <- randomForest(as.factor(left)~., data=training)
importance(myforest)
varImpPlot(myforest)
predForest <- predict(myforest, validation)
confMatrix <- table(validation$left, predForest)
missClass <- 1 - sum(diag(confMatrix))/sum(confMatrix)
accuracyValue <- sum(diag(confMatrix))/sum(confMatrix)
accuracyValue
